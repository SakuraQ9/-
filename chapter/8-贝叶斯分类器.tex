\section{贝叶斯分类器}

\subsection{贝叶斯思维简单解读}
笔者第一次听到贝叶斯这个名字，是在高三复习期间，市面上的一些秒杀大招辅导资料中介绍的。第二次听到贝叶斯这个名字，是在大一暑假自学宋浩老师的《概率论与数理统计》课程。第三次听到贝叶斯这个名字，便是大二上自学西瓜书的贝叶斯决策论这一章了。当时宋浩老师强调了一句话，令我至今记忆犹新：\textbf{证据并不应该直接决定你的看法，而是更新你的看法}。

贝叶斯思想在统计学习中起着举足轻重的作用，也是经典机器学习的两大流派之一，其核心思想凝聚成了一个十分优美的公式——贝叶斯定理。
\setcounter{equation}{0} %新的一章，将编号公式重设为1
\begin{equation}P(A\mid B)=\frac{P(B\mid A)\cdot P(A)}{P(B)}\end{equation}

机器学习可以理解为通过观测数据（X）推测结果（y）。同时学习推断规则（c），使得推断结果$\hat y=c(X)$与真实值 y 误差尽可能的小。而贝叶斯思维又是什么呢？让我们从以下四个问题出发：

\subsubsection{当我们一无所知时，如何进行推断？}
假设我们第一次接触硬币正反的问题，什么都不知道。因为一无所知，只能预测正面和反面的概率都是0.5。

假设我们虽然第一次接触硬币问题，但神告诉我们这种硬币出现正面的概率$\mathfrak{p}(1)=0.8$ ，反面的概率是$p(0)=0.2$。在这种情况下，我们就会倾向于预测结果是正面，且预测错误的概率是$1-p(1)=p(0)=0.2$  。

此处的 $\text{p(1)=0.8 和 p(0)=0.2}$ 就叫做\textbf{先验概率}（prior probability），指的是在观测前我们就已知的结果概率分布$\mathrm{p(y)}$。此处我们不需要观测硬币尺寸，就可以大胆推测硬币的正反。

\subsubsection{当我们有了更多信息，该如何利用它们？}
显然，前文提到的估算方法是很不准确的，因为没有考虑到硬币的属性。而且现实情况中我们往往可以观测到硬币的一些属性，而非完全一无所知。因此，我们尝试回答：“当我观测到硬币大小时，它正面朝上的概率是多少？”用数学语言表达就是估计$p(y=1|X)$ 。相似的， $p(y=0|X)$代表当我们观测到硬币属性X时，它被投掷后是反面的概率。

我们给$p(y=1|X)$  和   $p(y=0|X)$起了个名字，叫做\textbf{后验概率}（posterior probability），指的是在观测到X后我们对结果y的估计。和 $\text{p(y=1)}$不同，它不是计算$y=1$的概率，而是计算仅当X被观测到时$y=1$的概率。

先验概率和后验概率之间的关系是什么？简单来看，后验概率可以被看做是对先验概率的一种“更加细致的刻画和更新”，因为此时我们观测到了X，有了额外的信息。所以后验概率比先验概率更有意义，因为引入了额外的观测信息，所以预测的准确度得到了加强。而大部分机器学习模型尝试得到的，就是后验概率。

\subsubsection{如何得到后验概率？为什么要引入贝叶斯公式？}
后验概率无法直接获得，因此我们需要找到方法来计算它，而解决方法就是引入贝叶斯公式。后验概率这种表达叫做条件概率（conditional probability）。

\textbf{贝叶斯决策的预测值是选取后验概率最大的结果}。在二分类问题中，也就是对比$p(y=1|X)\text{与}p(y=0|X)$的结果，取最大值。
\subsubsection{为什么贝叶斯决策理论是“最优的”？}
因为$p(y=0|X)=1-p(y=1|X)$，也就是“观测到X并预测为反面的错误概率“就是“观测到X并预测为正面的后验概率”。

因此只要观测到X，并选择后验概率最大的结果，就可以最小化预测的错误概率。这个结论对所有观测值X均成立，因此只要按照这个预测逻辑，那么就可以保证预测的错误概率最小化，所以才叫做“最优”。

\subsection{贝叶斯决策论}
\textbf{贝叶斯决策论(Bayesian Decision Theory)是在概率框架下实施决策的基本理论}。其思想已经简单的在上期做了介绍，本期主要呈现核心理论知识。

给定 N 个类别，令$\lambda ij$代表将第 j 类样本误分类为第 i 类所产生的损失，则基于后验概率将样本$x$分到第 i 类的条件风险为： 
\begin{equation}R(c_i\mid\boldsymbol{x})=\sum_{j=1}^N\lambda_{ij}P(c_j\mid\boldsymbol{x})\end{equation}

贝叶斯判定准则 (Bayes decision rule)： 
\begin{equation}h^*(\boldsymbol{x})=\underset{c\in\mathcal{Y}}{\operatorname*{\arg\min}}R(c\mid\boldsymbol{x})\end{equation}
式（3）中的$\mathsf{h}^{*}$称为\textbf{贝叶斯最优分类器}(Bayes optimal classifier)，其总体风险称为\textbf{
贝叶斯风险} (Bayes risk)，该式反映了学习性能的理论上限。

$P(c\mid x)$难以在现实任务中直接获得，从这个角度来看，机器学习所要实现的是基于有限的训练样本尽可能准确地估计出后验概率。通常有两种判别方式：

（1）\textbf{判别式(Discriminative)模型}，其思路为直接对  $P(c\mid x)$建模，代表有：决策树、BP神经网络、SVM；

（2）\textbf{生成式(Generative)模型}，其思路是先对联合概率分布$P(c\mid x)$建模，再由此获得$P(c\mid x)$  。获得方法：$P(c\mid x)=\frac{P(x,c)}{P(x)}$  。代表是贝叶斯分类器。

这里需要强调的是:\textbf{贝叶斯分类器$!=$贝叶斯学习}

下面我们来介绍一种常用的参数估计方法——\textbf{极大似然估计}。我们先假设某种概率分布形式，再基于训练样例对参数进行估计。假定$P(x\mid c)$具有确定的概率分布形式，且被参数$\theta_{c}$唯一确定，则任务就是利用训练集 D 来估计参数$\theta_{c}$   。

$\theta_{c}$对于训练集 D 中第 c 类样本组成的集合 $D_{c}$的似然(Likelihood)为：
\begin{equation}P(D_c\mid\theta_c)=\prod_{x\in D_c}P(x\mid\theta_c)\end{equation}

连乘易造成下溢，因此通常使用对数似然 (Log-Likelihood)： 
\begin{equation}LL(\theta_c)=\log P(D_c\mid\theta_c)=\sum_{x\in D_c}\log P(x\mid\theta_c)\end{equation}

于是, $\theta_{c}$的极大似然估计为：
\begin{equation}\hat{\theta}_c=\arg\max_{\theta_c}LL(\theta_c)\end{equation}

由此观之，\textbf{估计结果的准确性严重依赖于所假设的概率分布形式是否符合潜在的真实分布！}

\subsection{朴素贝叶斯分类器}
我们直接由贝叶斯公式说开去： 
\begin{equation}P(c\mid x)=\frac{P(c)\boxed{P(x\mid c)}}{P(x)}\end{equation}

方框部分的获取难度很大，其主要障碍是：所有属性上的联合概率难以从有限训练样本估计获得；组合爆炸；样本稀疏。

基本思路：假设属性相互独立。

\begin{equation}P(c\mid x)=\frac{P(c)P(x\mid c)}{P(x)}=\frac{P(c)}{P(x)}\prod_{i=1}^dP(x_i\mid c)\end{equation}

d 为属性数，$x_{i}$为 x 在第 i 个属性上的取值$P(X)$对所有类别相同，于是 
\begin{equation}h_{nb}(x)=\arg\max_{c\in\mathcal{Y}}P(c)\prod_{i=1}^dP(x_i\mid c)\end{equation}

估计$P(c)$: $P(c)=\frac{|D_c|}{|D|}$ ;

估计$P(X|c)$:

（1）对离散属性，令  $D_{c,x_{i}}$表示 $D_{c}$中在第 i 个属性上取值为 $x_{i}$的样本组成的集合，则 
\begin{equation}P(x_i\mid c)=\frac{|D_{c,x_i}|}{|D_c|}\end{equation}

(2)对连续属性，考虑概率密度函数，假定$p(x_i\mid c)\sim\mathcal{N}(\mu_{c,i},\sigma_{c,i}^2)$则有：
\begin{equation}p(x_i\mid c)=\frac{1}{\sqrt{2\pi}\sigma_{c,i}}\exp\left(-\frac{(x_i-\mu_{c,i})^2}{2\sigma_{c,i}^2}\right)\end{equation}

若某个属性值在训练集中没有与某个类同时出现过，则直接计算会出现问题，因为概率连乘将“抹去”其他属性提供的信息。此时需要进行\textbf{拉普拉斯修正}。

令 N 表示训练集 D 中可能的类别数，$N_{i}$表示第 i 个属性可能的取值数： 
\begin{equation}\hat{P}(c)=\frac{|D_c|+1}{|D|+N}\end{equation}
\begin{equation}\hat{P}(x_i\mid c)=\frac{|D_{c,x_i}|+1}{|D_c|+N_i}\end{equation}

此法假设了属性值与类别的均匀分布，这是额外引入的 bias(偏置项,也称函数的截距)。